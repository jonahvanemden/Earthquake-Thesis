{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (1.13.1)\n",
      "Requirement already satisfied: pillow in /opt/anaconda3/lib/python3.12/site-packages (10.4.0)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.12/site-packages (3.9.2)\n",
      "Requirement already satisfied: numpy<2.3,>=1.22.4 in /opt/anaconda3/lib/python3.12/site-packages (from scipy) (1.26.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scipy pillow matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: h5py in /opt/anaconda3/lib/python3.12/site-packages (3.11.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/anaconda3/lib/python3.12/site-packages (from h5py) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geopandas in /opt/anaconda3/lib/python3.12/site-packages (1.0.1)\n",
      "Requirement already satisfied: rasterio in /opt/anaconda3/lib/python3.12/site-packages (1.4.3)\n",
      "Requirement already satisfied: shapely in /opt/anaconda3/lib/python3.12/site-packages (2.0.6)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (4.66.5)\n",
      "Requirement already satisfied: numpy>=1.22 in /opt/anaconda3/lib/python3.12/site-packages (from geopandas) (1.26.4)\n",
      "Requirement already satisfied: pyogrio>=0.7.2 in /opt/anaconda3/lib/python3.12/site-packages (from geopandas) (0.10.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from geopandas) (24.1)\n",
      "Requirement already satisfied: pandas>=1.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from geopandas) (2.2.3)\n",
      "Requirement already satisfied: pyproj>=3.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from geopandas) (3.6.1)\n",
      "Requirement already satisfied: affine in /opt/anaconda3/lib/python3.12/site-packages (from rasterio) (2.4.0)\n",
      "Requirement already satisfied: attrs in /opt/anaconda3/lib/python3.12/site-packages (from rasterio) (23.1.0)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.12/site-packages (from rasterio) (2025.1.31)\n",
      "Requirement already satisfied: click>=4.0 in /opt/anaconda3/lib/python3.12/site-packages (from rasterio) (8.1.7)\n",
      "Requirement already satisfied: cligj>=0.5 in /opt/anaconda3/lib/python3.12/site-packages (from rasterio) (0.7.2)\n",
      "Requirement already satisfied: click-plugins in /opt/anaconda3/lib/python3.12/site-packages (from rasterio) (1.1.1)\n",
      "Requirement already satisfied: pyparsing in /opt/anaconda3/lib/python3.12/site-packages (from rasterio) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.4.0->geopandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.4.0->geopandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.4.0->geopandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=1.4.0->geopandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install geopandas rasterio shapely tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import geopandas as gpd\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import cv2\n",
    "import h5py\n",
    "from shapely.geometry import box\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing \n",
    "- Turkey buildings: https://data.humdata.org/dataset/hotosm_tur_buildings \n",
    "- Turkey destroyed buildings: https://data.humdata.org/dataset/hotosm_tur_destroyed_buildings \n",
    "- Maxar open data for pre disaster tiff files of satellite images: https://www.maxar.com/open-data\n",
    "- QuickQuakeBuildings dataset already containing post disaster images and building footprints, also includes quad codes to obtain pre disaster images of same region and information on the pre defined folds: https://github.com/ya0-sun/PostEQ-SARopt-BuildingDamage?tab=readme-ov-file \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- the following code will limit the large geojson of building footprints to our area of interest. \n",
    "- This was done because the processing of the original geojson took too long.\n",
    "- Only run this if you do not yet have the filtered geojson loaded! It will take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geojson_path = \"/Users/jonahvanemden/Desktop/thesis 2/hotosm_tur_buildings_polygons_geojson(1)/hotosm_tur_buildings_polygons_geojson.geojson\"\n",
    "# tif_folder = \"/Users/jonahvanemden/Desktop/thesis 2/tif folder\"\n",
    "\n",
    "# buildings = gpd.read_file(geojson_path)  \n",
    "\n",
    "# def get_tif_bounds(tif_path):\n",
    "#     with rasterio.open(tif_path) as src:\n",
    "#         return src.bounds  \n",
    "\n",
    "# all_bounds = [get_tif_bounds(os.path.join(tif_folder, tif)) for tif in os.listdir(tif_folder) if tif.endswith(\".tif\")]\n",
    "\n",
    "# min_x = min([b[0] for b in all_bounds])\n",
    "# min_y = min([b[1] for b in all_bounds])\n",
    "# max_x = max([b[2] for b in all_bounds])\n",
    "# max_y = max([b[3] for b in all_bounds])\n",
    "\n",
    "# combined_bounds = (min_x, min_y, max_x, max_y)\n",
    "\n",
    "# sample_tif = os.path.join(tif_folder, [tif for tif in os.listdir(tif_folder) if tif.endswith(\".tif\")][0])\n",
    "# with rasterio.open(sample_tif) as src:\n",
    "#     tif_crs = src.crs\n",
    "\n",
    "# buildings = buildings.to_crs(tif_crs)\n",
    "\n",
    "# combined_box = box(*combined_bounds)\n",
    "\n",
    "\n",
    "# filtered_buildings = buildings[buildings.intersects(combined_box)]  \n",
    "\n",
    "# output_folder = \"/Users/jonahvanemden/Desktop/thesis 2/hotosm_tur_buildings_polygons_geojson(1)\"\n",
    "# os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# output_path = os.path.join(output_folder, \"filtered_buildings.geojson\")\n",
    "# filtered_buildings.to_file(output_path, driver=\"GeoJSON\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = \"/Users/jonahvanemden/Desktop/thesis 2/earthquake_building_dataset\"  \n",
    "damage_folder = os.path.join(base_folder, \"damaged\")\n",
    "intact_folder = os.path.join(base_folder, \"intact\")\n",
    "\n",
    "def get_unique_osm_ids(folder):\n",
    "    filenames = [f for f in os.listdir(folder) if f.endswith(\".mat\")]\n",
    "    osm_ids = set(f.split(\"_\")[0] for f in filenames)\n",
    "    return osm_ids\n",
    "\n",
    "damage_osm_ids = get_unique_osm_ids(damage_folder)\n",
    "intact_osm_ids = get_unique_osm_ids(intact_folder)\n",
    "\n",
    "print(f\"Buildings in damage: {len(damage_osm_ids)}\")\n",
    "print(f\"Buildings in intact: {len(intact_osm_ids)}\")\n",
    "\n",
    "total_unique_osm_ids = damage_osm_ids.union(intact_osm_ids)\n",
    "print(f\"Total buildings: {len(total_unique_osm_ids)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get pre earthquake building patches, create shadow masks and load splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing buildings: 100%|█████████████████████████████████████| 6799/6799 [19:09<00:00,  5.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved 3842 buildings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "geojson_path = \"/Users/jonahvanemden/Desktop/thesis 2/hotosm_tur_buildings_polygons_geojson(1)/filtered_buildings.geojson\"\n",
    "tif_folder = \"/Users/jonahvanemden/Desktop/thesis 2/tif folder\"\n",
    "output_folder = \"/Users/jonahvanemden/Desktop/thesis 2/Data/pre earthquake data/pre turkey earthquake patches\"\n",
    "damage_folder = \"/Users/jonahvanemden/Desktop/thesis 2/Data/earthquake_building_dataset/damaged\"\n",
    "intact_folder = \"/Users/jonahvanemden/Desktop/thesis 2/Data/earthquake_building_dataset/intact\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "def get_valid_osm_ids(folder):  # Make sure you only get images of the buildings of which there are post earthquake images.\n",
    "    return set(f.split(\"_\")[0] for f in os.listdir(folder) if f.endswith(\".mat\"))\n",
    "\n",
    "valid_osm_ids = get_valid_osm_ids(damage_folder).union(get_valid_osm_ids(intact_folder))\n",
    "\n",
    "buildings = gpd.read_file(geojson_path)\n",
    "\n",
    "sample_tif = [os.path.join(tif_folder, f) for f in os.listdir(tif_folder) if f.endswith(\".tif\")][0]\n",
    "with rasterio.open(sample_tif) as src:  # Make sure coordinate reference system is correct.\n",
    "    tif_crs = src.crs\n",
    "    pixel_size = src.res[0]\n",
    "\n",
    "buildings = buildings.to_crs(tif_crs)\n",
    "\n",
    "tif_files = [os.path.join(tif_folder, f) for f in os.listdir(tif_folder) if f.endswith(\".tif\")]\n",
    "\n",
    "buffer_distance = 16 * pixel_size  # Buffer distance of 16 pixels surrounding the building to match the images in the original QQB dataset.\n",
    "saved_count = 0\n",
    "\n",
    "for i, row in tqdm(buildings.iterrows(), total=len(buildings), desc=\"Processing buildings\", ncols=100):\n",
    "    osm_id = str(row.get(\"osm_id\", f\"unknown_{i}\"))\n",
    "\n",
    "    if osm_id not in valid_osm_ids:\n",
    "        continue\n",
    "\n",
    "    geom = row['geometry'].buffer(buffer_distance)\n",
    "    found = False\n",
    "\n",
    "    for tif_path in tif_files:\n",
    "        with rasterio.open(tif_path) as src:\n",
    "            if not geom.intersects(box(*src.bounds)):\n",
    "                continue \n",
    "\n",
    "            try:\n",
    "                bbox = geom.bounds  \n",
    "                window = rasterio.windows.from_bounds(*bbox, transform=src.transform)\n",
    "                window = window.round_offsets().round_lengths()\n",
    "\n",
    "                out_image = src.read(window=window)\n",
    "\n",
    "                out_image[out_image == src.nodata] = 0\n",
    "\n",
    "                out_image = np.moveaxis(out_image, 0, -1)\n",
    "                out_image_uint8 = np.clip(out_image, 0, 255).astype(np.uint8)\n",
    "\n",
    "                img = Image.fromarray(out_image_uint8)\n",
    "                output_path = os.path.join(output_folder, f\"{osm_id}_opt_pre.png\")\n",
    "                img.save(output_path)\n",
    "\n",
    "                saved_count += 1\n",
    "                found = True\n",
    "                break\n",
    "\n",
    "            except Exception as e:\n",
    "                continue\n",
    "\n",
    "    if not found:\n",
    "        warnings.warn(f\"Building {i} OSM ID: {osm_id} not found\")\n",
    "\n",
    "\n",
    "print(f\"saved {saved_count} buildings\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Get pre earthquake building patches from destroyed buildings since they have a different geojson on HOTOSM but the process stays the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing buildings: 100%|█████████████████████████████████████| 3239/3239 [00:50<00:00, 64.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved 169 buildings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "geojson_path = \"/Users/jonahvanemden/Desktop/thesis 2/hotosm_tur_destroyed_buildings_polygons_geojson.geojson\"\n",
    "tif_folder = \"/Users/jonahvanemden/Desktop/thesis 2/tif folder\"\n",
    "output_folder = \"/Users/jonahvanemden/Desktop/thesis 2/Data/pre earthquake data/pre turkey damaged patches\"\n",
    "damage_folder = \"/Users/jonahvanemden/Desktop/thesis 2/Data/earthquake_building_dataset/damaged\"\n",
    "intact_folder = \"/Users/jonahvanemden/Desktop/thesis 2/Data/earthquake_building_dataset/intact\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "def get_valid_osm_ids(folder):\n",
    "    return set(f.split(\"_\")[0] for f in os.listdir(folder) if f.endswith(\".mat\"))\n",
    "\n",
    "valid_osm_ids = get_valid_osm_ids(damage_folder).union(get_valid_osm_ids(intact_folder))\n",
    "\n",
    "buildings = gpd.read_file(geojson_path)\n",
    "\n",
    "sample_tif = [os.path.join(tif_folder, f) for f in os.listdir(tif_folder) if f.endswith(\".tif\")][0]\n",
    "with rasterio.open(sample_tif) as src:\n",
    "    tif_crs = src.crs\n",
    "    pixel_size = src.res[0]\n",
    "\n",
    "buildings = buildings.to_crs(tif_crs)\n",
    "\n",
    "tif_files = [os.path.join(tif_folder, f) for f in os.listdir(tif_folder) if f.endswith(\".tif\")]\n",
    "\n",
    "buffer_distance = 16 * pixel_size\n",
    "saved_count = 0\n",
    "\n",
    "for i, row in tqdm(buildings.iterrows(), total=len(buildings), desc=\"Processing buildings\", ncols=100):\n",
    "    osm_id = str(row.get(\"osm_id\", f\"unknown_{i}\"))\n",
    "\n",
    "    if osm_id not in valid_osm_ids:\n",
    "        continue\n",
    "\n",
    "    geom = row['geometry'].buffer(buffer_distance)\n",
    "    found = False\n",
    "\n",
    "    for tif_path in tif_files:\n",
    "        with rasterio.open(tif_path) as src:\n",
    "            if not geom.intersects(box(*src.bounds)):\n",
    "                continue  \n",
    "\n",
    "            try:\n",
    "               \n",
    "                bbox = geom.bounds  \n",
    "                window = rasterio.windows.from_bounds(*bbox, transform=src.transform)\n",
    "                window = window.round_offsets().round_lengths()\n",
    "\n",
    "                out_image = src.read(window=window)\n",
    "\n",
    "                out_image[out_image == src.nodata] = 0\n",
    "\n",
    "                out_image = np.moveaxis(out_image, 0, -1)\n",
    "                out_image_uint8 = np.clip(out_image, 0, 255).astype(np.uint8)\n",
    "\n",
    "                img = Image.fromarray(out_image_uint8)\n",
    "                output_path = os.path.join(output_folder, f\"{osm_id}_opt_pre.png\")\n",
    "                img.save(output_path)\n",
    "\n",
    "                saved_count += 1\n",
    "                found = True\n",
    "                break\n",
    "\n",
    "            except Exception as e:\n",
    "                continue\n",
    "\n",
    "    if not found:\n",
    "        warnings.warn(f\"Building {i} OSM ID: {osm_id} not found\")\n",
    "\n",
    "\n",
    "print(f\"saved {saved_count} buildings\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check if buildings have not been saved in two folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I noticed that one building that was in the pre earthquake damaged folder was also saved in the pre earthquake intact folder.\n",
    "# The following code finds that building and removes it from the intact folder since it was present in the post earthquake damaged folder.\n",
    "\n",
    "base_folder = \"/Users/jonahvanemden/Desktop/thesis 2/Data/earthquake_building_dataset\"\n",
    "damage_folder = os.path.join(base_folder, \"damaged\")\n",
    "output_folder = \"/Users/jonahvanemden/Desktop/thesis 2/Data/pre earthquake data/pre turkey earthquake patches\"\n",
    "\n",
    "def get_unique_osm_ids(folder):\n",
    "    filenames = [f for f in os.listdir(folder) if f.endswith(\".mat\")]\n",
    "    osm_ids = set(f.split(\"_\")[0] for f in filenames)\n",
    "    return osm_ids\n",
    "\n",
    "def get_saved_osm_ids(folder):\n",
    "    filenames = [f for f in os.listdir(folder) if f.endswith(\"_opt_pre.png\")]\n",
    "    osm_ids = set(f.split(\"_\")[0] for f in filenames)\n",
    "    return osm_ids\n",
    "\n",
    "damage_osm_ids = get_unique_osm_ids(damage_folder)\n",
    "saved_osm_ids = get_saved_osm_ids(output_folder)\n",
    "\n",
    "damage_saved_ids = saved_osm_ids.intersection(damage_osm_ids)\n",
    "\n",
    "for osm_id in damage_saved_ids:\n",
    "    print(osm_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the image from the intact folder since it is in the damaged folder for post images from QQB.\n",
    "output_folder = \"/Users/jonahvanemden/Desktop/thesis 2/Data/pre earthquake data/pre turkey earthquake patches\"\n",
    "\n",
    "osm_id_to_remove = list(damage_saved_ids)[0]  \n",
    "\n",
    "filename = f\"{osm_id_to_remove}_opt_pre.png\"\n",
    "file_path = os.path.join(output_folder, filename)\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    os.remove(file_path)\n",
    "    print(f\"Removed: {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Get the shadow masks for the pre earthquake images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pre turkey damaged patches images: 100%|██████████| 170/170 [00:00<00:00, 244.56it/s]\n",
      "Processing pre turkey earthquake patches images: 100%|██████████| 3841/3841 [00:10<00:00, 359.83it/s]\n"
     ]
    }
   ],
   "source": [
    "def threshold_shadow_segmentation(image):\n",
    "    \"\"\"\n",
    "    Segment shadows in the image using Otsu's thresholding method.\n",
    "    Shadows are converted to white (255), background to black (0).\n",
    "    \"\"\"\n",
    "    gray_image = image.convert('L')\n",
    "    gray_array = np.array(gray_image)\n",
    "\n",
    "    _, shadow_mask = cv2.threshold(gray_array, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)  # Apply Otsu's thresholding (shadows will be 0, background 255).\n",
    "\n",
    "    shadow_mask = 255 - shadow_mask  # Invert the mask so shadows become white and background becomes black.\n",
    "\n",
    "    return Image.fromarray(shadow_mask)\n",
    "\n",
    "\n",
    "def process_shadow_masks(input_folder, output_folder):\n",
    "    \"\"\"\n",
    "    Process all images in the input_folder to generate shadow masks.\n",
    "    Saves the masks in the output_folder with filenames formatted as osm_id_pre_shadow.png.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    for filename in tqdm(os.listdir(input_folder), desc=f\"Processing {os.path.basename(input_folder)} images\"):\n",
    "        if filename.endswith('.png'):\n",
    "            osm_id = filename.split('_')[0]\n",
    "            \n",
    "            image_path = os.path.join(input_folder, filename)\n",
    "        \n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "            shadow_mask = threshold_shadow_segmentation(image)\n",
    "            \n",
    "            output_filename = f\"{osm_id}_pre_shadow.png\"\n",
    "            output_path = os.path.join(output_folder, output_filename)\n",
    "            shadow_mask.save(output_path)\n",
    "\n",
    "damaged_images_folder = '/Users/jonahvanemden/Desktop/thesis 2/Data/pre earthquake data/pre turkey damaged patches'\n",
    "intact_images_folder = '/Users/jonahvanemden/Desktop/thesis 2/Data/pre earthquake data/pre turkey earthquake patches'\n",
    "\n",
    "damaged_output_folder = '/Users/jonahvanemden/Desktop/thesis 2/Data/pre shadows/Damaged'\n",
    "intact_output_folder = '/Users/jonahvanemden/Desktop/thesis 2/Data/pre shadows/Intact'\n",
    "\n",
    "process_shadow_masks(damaged_images_folder, damaged_output_folder)\n",
    "\n",
    "process_shadow_masks(intact_images_folder, intact_output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Get shadow masks for post earthquake images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing damaged: 100%|████████████████████████████████████████| 169/169 [00:00<00:00, 246.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jonahvanemden/Desktop/thesis 2/Data/post shadows/Damaged: 169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing intact: 100%|███████████████████████████████████████| 3860/3860 [00:13<00:00, 294.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jonahvanemden/Desktop/thesis 2/Data/post shadows/Intact: 3860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# The methodology for obtaining shadow masks for the post images is different since they are stored as .mat files.\n",
    "\n",
    "def read_mat_image(mat_path):\n",
    "    with h5py.File(mat_path, 'r') as f:\n",
    "        key = list(f.keys())[0]\n",
    "        array = np.array(f[key])\n",
    "        if array.shape[0] == 3:\n",
    "            array = np.transpose(array, (1, 2, 0))\n",
    "        return array\n",
    "\n",
    "\n",
    "def process_mat_folder(mat_folder, output_folder):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    processed_osm_ids = set()\n",
    "    grouped_mats = {}\n",
    "\n",
    "    for fname in sorted(os.listdir(mat_folder)):\n",
    "        if not fname.endswith('_opt.mat'):\n",
    "            continue\n",
    "        osm_id = fname.split(\"_\")[0]\n",
    "        grouped_mats.setdefault(osm_id, []).append(fname)\n",
    "\n",
    "    saved_count = 0\n",
    "\n",
    "    for osm_id, files in tqdm(grouped_mats.items(), desc=f\"Processing {os.path.basename(mat_folder)}\", ncols=100):\n",
    "        if osm_id in processed_osm_ids:\n",
    "            continue\n",
    "\n",
    "        mat_path = os.path.join(mat_folder, files[0])\n",
    "        try:\n",
    "            img_array = read_mat_image(mat_path)\n",
    "            img_array = np.clip(img_array, 0, 255).astype(np.uint8)\n",
    "            img_pil = Image.fromarray(img_array)\n",
    "\n",
    "            shadow_mask = threshold_shadow_segmentation(img_pil)\n",
    "\n",
    "            out_path = os.path.join(output_folder, f\"{osm_id}_post_shadow.png\")\n",
    "            shadow_mask.save(out_path)\n",
    "\n",
    "            processed_osm_ids.add(osm_id)\n",
    "            saved_count += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"{mat_path}: {e}\")\n",
    "\n",
    "    print(f\"{output_folder}: {saved_count}\")\n",
    "\n",
    "damaged_post_folder = \"/Users/jonahvanemden/Desktop/thesis 2/Data/earthquake_building_dataset/damaged\"\n",
    "intact_post_folder = \"/Users/jonahvanemden/Desktop/thesis 2/Data/earthquake_building_dataset/intact\"\n",
    "\n",
    "damaged_output = \"/Users/jonahvanemden/Desktop/thesis 2/Data/post shadows/Damaged\"\n",
    "intact_output = \"/Users/jonahvanemden/Desktop/thesis 2/Data/post shadows/Intact\"\n",
    "\n",
    "process_mat_folder(damaged_post_folder, damaged_output)\n",
    "process_mat_folder(intact_post_folder, intact_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create splits linking all relevant images and information based on the pre defined splits from the QQB dataset. Only buildings that exist in the pre and post images are used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold-1.txt 801 samples saved to /Users/jonahvanemden/Desktop/thesis 2/Data/split_csvs/fold-1.csv\n",
      "fold-2.txt 804 samples saved to /Users/jonahvanemden/Desktop/thesis 2/Data/split_csvs/fold-2.csv\n",
      "fold-3.txt 803 samples saved to /Users/jonahvanemden/Desktop/thesis 2/Data/split_csvs/fold-3.csv\n",
      "fold-4.txt 802 samples saved to /Users/jonahvanemden/Desktop/thesis 2/Data/split_csvs/fold-4.csv\n",
      "fold-5.txt 800 samples saved to /Users/jonahvanemden/Desktop/thesis 2/Data/split_csvs/fold-5.csv\n"
     ]
    }
   ],
   "source": [
    "split_txt_folder = \"/Users/jonahvanemden/Desktop/thesis 2/Data split\"\n",
    "output_csv_folder = \"/Users/jonahvanemden/Desktop/thesis 2/Data/split_csvs\"\n",
    "os.makedirs(output_csv_folder, exist_ok=True)\n",
    "\n",
    "folders = {\n",
    "    0: { \n",
    "        \"pre_optical\": \"/Users/jonahvanemden/Desktop/thesis 2/Data/pre earthquake data/pre turkey earthquake patches\",\n",
    "        \"pre_shadow\": \"/Users/jonahvanemden/Desktop/thesis 2/Data/pre shadows/Intact\",\n",
    "        \"post\": \"/Users/jonahvanemden/Desktop/thesis 2/Data/earthquake_building_dataset/intact\",\n",
    "        \"post_shadow\": \"/Users/jonahvanemden/Desktop/thesis 2/Data/post shadows/Intact\",\n",
    "    },\n",
    "    1: {  \n",
    "        \"pre_optical\": \"/Users/jonahvanemden/Desktop/thesis 2/Data/pre earthquake data/pre turkey damaged patches\",\n",
    "        \"pre_shadow\": \"/Users/jonahvanemden/Desktop/thesis 2/Data/pre shadows/Damaged\",\n",
    "        \"post\": \"/Users/jonahvanemden/Desktop/thesis 2/Data/earthquake_building_dataset/damaged\",\n",
    "        \"post_shadow\": \"/Users/jonahvanemden/Desktop/thesis 2/Data/post shadows/Damaged\",\n",
    "    }\n",
    "}\n",
    "\n",
    "def get_if_exists(path):\n",
    "    return path if os.path.exists(path) else None\n",
    "\n",
    "for split_filename in os.listdir(split_txt_folder):  # Process each split .txt file with pre defined 5 folds.\n",
    "    if not split_filename.endswith(\".txt\"):\n",
    "        continue\n",
    "\n",
    "    split_path = os.path.join(split_txt_folder, split_filename)\n",
    "    records = []\n",
    "\n",
    "    with open(split_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if \",\" not in line:\n",
    "            continue\n",
    "\n",
    "        sample, label_str = line.split(\",\")\n",
    "        label = int(label_str)\n",
    "        osm_id = os.path.basename(sample)\n",
    "\n",
    "        fldr = folders[label]\n",
    "\n",
    "        paths = {\n",
    "            \"osm_id\": osm_id,\n",
    "            \"label\": label,\n",
    "            \"pre_optical\": get_if_exists(os.path.join(fldr[\"pre_optical\"], f\"{osm_id}_opt_pre.png\")),\n",
    "            \"pre_shadow\": get_if_exists(os.path.join(fldr[\"pre_shadow\"], f\"{osm_id}_pre_shadow.png\")),\n",
    "            \"post_optical_mat\": get_if_exists(os.path.join(fldr[\"post\"], f\"{osm_id}_opt.mat\")),\n",
    "            \"post_optical_footprint_mat\": get_if_exists(os.path.join(fldr[\"post\"], f\"{osm_id}_optftp.mat\")),\n",
    "            \"post_shadow\": get_if_exists(os.path.join(fldr[\"post_shadow\"], f\"{osm_id}_post_shadow.png\")),\n",
    "        }\n",
    "\n",
    "        if all(paths[k] for k in paths if k not in [\"osm_id\", \"label\"]):\n",
    "            records.append(paths)\n",
    "\n",
    "    output_path = os.path.join(output_csv_folder, split_filename.replace(\".txt\", \".csv\"))\n",
    "    pd.DataFrame(records).to_csv(output_path, index=False)\n",
    "    print(f\"{split_filename} {len(records)} samples saved to {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
